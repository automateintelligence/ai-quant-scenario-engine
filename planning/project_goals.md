# Backtesting Module
- This module is designed for backtesting automation by generating Monte Carlo simulations supplemented with automated stochastic modeling of real data from the underlying instrument.

- The backtesting module shall be independent of the strategy module. It must be agnostic of strategy and instruments, or at a minimum provide the capability for the common variety of instruments like stocks, ETFs, Mutual Funds, bonds, commodities, currencies, etc. For the MVP, we will be satisfied with stocks, ETFs, and Mutual Funds. 

- The automation of the stochastic modeling of the underlying instrument will be based on fitting the right distribution to the historical timeseries data. This could be a Gaussian, Laplacian, or other distribution that best fits the data but also properly represents the chaotic and unpredictable nature of the market, e.g. distribution tails accurately represent the possibility of black swan events. 

- Once the stochastic model is generated, it is relatively simple to create N (500-10000) independent timeseries for Monte Carlo analysis. We built the timeseries by randomly drawing from the distribution for price changes at each timestep. 

- I haven't figured out how to integrate the backtesting with the strategy. The backtesting module will generate a Monte Carlo matrix of timeseries in a Pandas dataframe. The rows represent independent timeseries, and the columns represent time steps. This is not event-driven analysis, this is vectorized analysis that can be done very quickly using numpy or faster libraries. The strategy will only be allowed to use event-driven logic 
- The strategy module will act upon and provide timestamped execution signals back to the backtesting module for each row. The backtesting module will then apply these signals and generate reports of the performance results, including summaries, charts, and tables.

- I have three products in mind for my financial division. 1) A portfolio asset allocation optimizer based on efficient frontier and entropy maximization. 2) A long-term portfolio trading strategy optimizer. Similar to #3, but focused on safer portfolio strategies. 3) Right now, I am focused on a single stock and option trading algo optimization. High-risk, high-reward strategies. 

- Here is what I really want. Modular designs that I can run on my virtual private server (VPS) with CPU only, no GPU right now. Maximize parallelization and vector maths. I am open to rules-based strategies; real-time LLM-enabled market, media, and social media analysis; and machine learning based models. Containerized services, like VectorBT, are acceptable options if they are worth the added complexity. I currently have paid API access to multiple LLM foundation models: OpenAI, You.com, and Anthropic. If we are successful, I will probably progress to GPU-based models and API services like Amazon Bedrock or Google Cloud. For data and trading services, I already have access to the Schwab API. I can sign up for the Merrill Lynch API if that provides capabilities that Schwab does not. I have stock and option trading level II accounts at Merrill and Schwab.

- I envision a backtesting module, a strategy module, and a strategy optimization module. I am very familiar with a variety of optimization methods that I would like to employ to efficiently optimize strategy parameters and test them with massive parallelization. I could write all my own modules, but if I can leverage existing open source libraries, I want to do that first, but it must be in a way that makes sense and is relatively easy to use as I just described.
- Now that you have done all this research, please recommend a system that I can build to an MVP quickly to start evaluating single stock and option strategies. My first goal is to compare risk and reward surfaces for stock trades versus option trades on the same underlying stock. User-initiated CLI or GUI trade execution is a nice-to-have, but not a must for MVP. I can trade on the Thinkorswim platform or on the brokerage websites if I must. Then I can gradually increase complexity and features as we move forward.
